{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3646d7",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0812715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254ee67",
   "metadata": {},
   "source": [
    "Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1293e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accident_df(subset=\"standard_small\", n_rows=10000, is_refined=False):\n",
    "    warnings.warn(\"This function is outdated and should not be used.\")\n",
    "    if is_refined:\n",
    "        df = get_accident_df(subset=subset, n_rows=n_rows, is_refined=False)\n",
    "        return refine_df(df)\n",
    "\n",
    "    if subset == \"standard_small\":\n",
    "        return pd.read_csv(\"DataSubsetRaw.csv\")\n",
    "    if subset == \"new\":\n",
    "        n = 3513617 #number of rows in the dataset\n",
    "        s = n_rows #number of rows to sample\n",
    "        skip = sorted(random.sample(range(1, n+1), n-s)) #rows to be skipped\n",
    "        return pd.read_csv(\"US_Accidents_June20.csv\", skiprows=skip)\n",
    "    if subset == \"all\":\n",
    "        return pd.read_csv(\"US_Accidents_June20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb4b11",
   "metadata": {},
   "source": [
    "Internal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8520eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_df(size=100):\n",
    "    n = 3513617 #number of rows in the dataset                          \n",
    "    s = size #number of rows to sample                                \n",
    "    skip = sorted(random.sample(range(1, n+1), n-s)) #rows to be skipped\n",
    "    return pd.read_csv(\"US_Accidents_June20.csv\", skiprows=skip)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec02fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_df(df):\n",
    "    df = change_column_names(df)\n",
    "    df = convert_to_metric(df)\n",
    "    df = timeStamp_df(df)\n",
    "    df = duration_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7c9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_names(df):\n",
    "    col_names = df.columns\n",
    "    col_names = [name.replace(\"_\", \"\") for name in col_names]\n",
    "    col_names = [name[:loc] if (loc := name.find(\"(\")) != -1 else name for name in col_names]\n",
    "    df.columns = col_names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9849e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_metric(df):\n",
    "    #miles to km\n",
    "    df[\"Distance\"] = df[\"Distance\"] * 1.60934\n",
    "\n",
    "    #F to C\n",
    "    df[\"Temperature\"] = (df[\"Temperature\"] - 32) * 5 / 9\n",
    "\n",
    "    #F to C\n",
    "    df[\"WindChill\"] = (df[\"WindChill\"] - 32) * 5 / 9\n",
    "\n",
    "    #inches of mercury to bar\n",
    "    df[\"Pressure\"] = df[\"Pressure\"] / 29.53\n",
    "\n",
    "    #miles to km\n",
    "    df[\"Visibility\"] = df[\"Visibility\"] * 1.60934\n",
    "\n",
    "    #mph to kph\n",
    "    df[\"WindSpeed\"] = df[\"WindSpeed\"] * 1.60934\n",
    "\n",
    "    #inches to cm\n",
    "    df[\"Precipitation\"] = df[\"Precipitation\"] * 2.54\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4334b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function converts Start_Time and End_Time data in dataframe to 'datetime64[ns]' datatype.\n",
    "def timeStamp_df(df):\n",
    "    df['StartTime'] = pd.to_datetime(df['StartTime'])\n",
    "    df['EndTime'] = pd.to_datetime(df['EndTime'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f67de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function creates column in df with duration data as dataype 'timedelta64[ns]'.\n",
    "def duration_df(df):\n",
    "    df['Duration'] = (df['EndTime']-df['StartTime'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b000402",
   "metadata": {},
   "source": [
    "Functions for population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function creates dataframe with accident counts per city, state.  \n",
    "def accidentCounts(df):\n",
    "    df2 = df.groupby(['City', 'State']).count().reset_index()\n",
    "    df_counts = df2[['City','State','ID']]\n",
    "    df_counts = df_counts.rename(columns={'ID': 'Counts'})\n",
    "    return df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function loads and  dataframe with population data\n",
    "def populationData():\n",
    "    df_population = pd.read_csv(\"CityPopulations.csv\")\n",
    "\n",
    "    state_names = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', \n",
    "     'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', \n",
    "     'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', \n",
    "     'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', \n",
    "     'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', \n",
    "     'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', \n",
    "     'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', \n",
    "     'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', \n",
    "     'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', \n",
    "     'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "\n",
    "    state_codes = ['AL', 'AK', 'AZ', 'AR', 'CA', \n",
    "     'CO', 'CT', 'DE', 'DC', 'FL', \n",
    "     'GA', 'HI', 'ID', 'IL', 'IN', \n",
    "     'IA', 'KS', 'KY', 'LA', 'ME', \n",
    "     'MD', 'MA', 'MI', 'MN', 'MS',\n",
    "     'MO', 'MT', 'NE', 'NV', 'NH', \n",
    "     'NJ', 'NM', 'NY', 'NC', 'ND',\n",
    "     'OH', 'OK', 'OR', 'PA', 'RI',\n",
    "     'SC', 'SD', 'TN', 'TX', 'UT', \n",
    "     'VT', 'VA', 'WA', 'WV', 'WI',\n",
    "     'WY']\n",
    "\n",
    "    df_population['State'] = df_population['State'].replace(state_names,state_codes)\n",
    "    #To make it easier to create bar plots with city, state as labels\n",
    "    df_population['City + State'] = df_population['City']+', '+df_population['State']\n",
    "    return df_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a44f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function merging population data and accident counts data. This function calls accidentCounts(df) and populationData()\n",
    "def mergedPopulationCounts(df):\n",
    "    df_counts = accidentCounts(df)\n",
    "    df_population = populationData()\n",
    "    df_merged = df_population.merge(df_counts)\n",
    "    df_merged['Counts per 100K'] = df_merged['Counts']/(df_merged['Population']/100000)\n",
    "    return df_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "name": "DataPreparation.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
